{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q-JdKSW_LtNG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3645,
     "status": "ok",
     "timestamp": 1733258401047,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 300
    },
    "id": "q-JdKSW_LtNG",
    "outputId": "6ac38453-eb3a-4abe-8593-51d30ee5429a"
   },
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8O2A9yXyWlBG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23322,
     "status": "ok",
     "timestamp": 1733258424366,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 300
    },
    "id": "8O2A9yXyWlBG",
    "outputId": "6ffee508-04ec-46e2-be2c-ec0a4d714d95"
   },
   "outputs": [],
   "source": [
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xiE1OK3dfcQuj9xp73mfcDpO",
   "metadata": {
    "executionInfo": {
     "elapsed": 19121,
     "status": "ok",
     "timestamp": 1733258461958,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 300
    },
    "id": "xiE1OK3dfcQuj9xp73mfcDpO",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UPVd72hXXfRb",
   "metadata": {
    "executionInfo": {
     "elapsed": 132,
     "status": "ok",
     "timestamp": 1733259065328,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 300
    },
    "id": "UPVd72hXXfRb"
   },
   "outputs": [],
   "source": [
    "# Initialize ChromaDB client with persistence\n",
    "client = chromadb.PersistentClient(path=\"gs://project-yelp/reviews_rag_chroma_reviews_db\")\n",
    "# Create or load a ChromaDB collection\n",
    "collection = client.get_or_create_collection(name=\"reviews_embeddings_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "C7M1BGDNWJJK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "executionInfo": {
     "elapsed": 165836,
     "status": "ok",
     "timestamp": 1733252076218,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 300
    },
    "id": "C7M1BGDNWJJK",
    "outputId": "287a212b-fd52-4f74-ed01-c0d45327e451"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('concatenated_reviews.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1602c8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PcMcCK3WZkK0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 249,
     "status": "ok",
     "timestamp": 1733256831666,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 300
    },
    "id": "PcMcCK3WZkK0",
    "outputId": "d1259ecb-1514-41ae-8714-929dd1d29875"
   },
   "outputs": [],
   "source": [
    "metadata_col = list(df)[:-1]\n",
    "print(metadata_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9I5ekT6LqOo",
   "metadata": {
    "id": "c9I5ekT6LqOo"
   },
   "outputs": [],
   "source": [
    "openai.api_key = \"lorem_ipsum\"\n",
    "# client = OpenAI()\n",
    "# Function to chunk text\n",
    "def chunk_text_with_overlap(text, token_limit=1000, overlap=50):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    start = 0\n",
    "\n",
    "    while start < len(words):\n",
    "        # Get the chunk\n",
    "        end = min(start + token_limit, len(words))\n",
    "        chunk = words[start:end]\n",
    "        chunks.append(\" \".join(chunk))\n",
    "\n",
    "        # Move the start pointer, including overlap\n",
    "        start += token_limit - overlap\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Function to generate embeddings for a chunk\n",
    "def get_embeddings(text):\n",
    "    response = openai.embeddings.create(\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        input=text\n",
    "    )\n",
    "    # print(response.data[0].embedding)\n",
    "    return np.array(response.data[0].embedding, dtype = np.float64)\n",
    "\n",
    "# Function to aggregate embeddings\n",
    "def aggregate_embeddings(embeddings, method=\"mean\"):\n",
    "    if method == \"mean\":\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    elif method == \"max\":\n",
    "        return np.max(embeddings, axis=0)\n",
    "    elif method == \"concat\":\n",
    "        return np.concatenate(embeddings, axis=0)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported aggregation method!\")\n",
    "\n",
    "# Function to process text: Chunk -> Embed -> Aggregate\n",
    "def process_text_for_embeddings(text, token_limit=1024, aggregation_method=\"mean\"):\n",
    "    # Step 1: Chunk the text\n",
    "    chunks = chunk_text_with_overlap(text, token_limit=token_limit)\n",
    "\n",
    "    # Step 2: Generate embeddings for each chunk\n",
    "    chunk_embeddings = [get_embeddings(chunk) for chunk in chunks]\n",
    "\n",
    "    # Step 3: Aggregate embeddings\n",
    "    aggregated_embedding = aggregate_embeddings(chunk_embeddings, method=aggregation_method)\n",
    "\n",
    "    return aggregated_embedding\n",
    "\n",
    "def store_embeddings_in_chromadb(df, text_col, metadata_col):\n",
    "    for _, row in df.iterrows():\n",
    "        text = row[text_col]\n",
    "        metadata_rows = row[metadata_col]\n",
    "\n",
    "        # Handle non-string text values\n",
    "        if not isinstance(text, str):\n",
    "            text = str(text) if not pd.isna(text) else \"\"\n",
    "\n",
    "        metadata = metadata_rows.to_dict()\n",
    "        unique_id = str(metadata.pop(\"business_id\"))\n",
    "\n",
    "        try:\n",
    "            # Generate embedding for the text\n",
    "            embedding = process_text_for_embeddings(text, token_limit=1024, aggregation_method=\"max\")\n",
    "            \n",
    "            # Add text, embedding, and metadata to ChromaDB\n",
    "            collection.add(\n",
    "                documents=[text],\n",
    "                embeddings=[embedding],\n",
    "                metadatas=[metadata],\n",
    "                ids=[unique_id]\n",
    "            )\n",
    "            print(f\"Successfully stored embedding for {unique_id}.\")\n",
    "        except ValueError as e:\n",
    "            print(f\"Error processing {unique_id}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38aa9def",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_embeddings_in_chromadb(df, \"concatenated_reviews\", metadata_col)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "sk2304 (Dec 2, 2024, 9:26:17â€¯PM)",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
